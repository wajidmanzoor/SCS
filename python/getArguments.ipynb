{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGraphForRun(s):\n",
    "    for i in s.split(\"\\n\"):\n",
    "        print(\"'\"+i+\"'\", end = \" \")\n",
    "    return s.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs =  \"\"\"graph7\n",
    "graph8.txt\n",
    "fat200\n",
    "GSE1730_q\n",
    "GSE10158_q\n",
    "orani\n",
    "ego-facebook\n",
    "grqc_q\n",
    "uc64\n",
    "government\n",
    "wiki-elec\n",
    "lastfm\n",
    "hepPh\n",
    "astroPh\n",
    "condmat\n",
    "Enron_q\n",
    "fb-pages\n",
    "brightkite\n",
    "livemocha\n",
    "gowalla\n",
    "citeseer\n",
    "com-dblp\n",
    "amazon_q\n",
    "youtube_q\n",
    "hyves_q\n",
    "skitter\n",
    "flixster\n",
    "patent_q\n",
    "soc-livejournal\n",
    "dblp-author\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'graph7' 'graph8.txt' 'fat200' 'GSE1730_q' 'GSE10158_q' 'orani' 'ego-facebook' 'grqc_q' 'uc64' 'government' 'wiki-elec' 'lastfm' 'hepPh' 'astroPh' 'condmat' 'Enron_q' 'fb-pages' 'brightkite' 'livemocha' 'gowalla' 'citeseer' 'com-dblp' 'amazon_q' 'youtube_q' 'hyves_q' 'skitter' 'flixster' 'patent_q' 'soc-livejournal' 'dblp-author' "
     ]
    }
   ],
   "source": [
    "graph_names = getGraphForRun(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPUArgs(path,graph_names):\n",
    "    df = pd.read_csv(path)\n",
    "    qid = []\n",
    "    for graph_name in graph_names:\n",
    "        l = []\n",
    "        num_vertex = df[df['file_name']==graph_name]['V'].values[0]\n",
    "        for core_value in [6,9,12,15,18,21,24]:\n",
    "            vert = np.random.randint(0,num_vertex)\n",
    "            l.append(vert)\n",
    "        qid.append(\" \".join(list(map(str,l))))\n",
    "    return qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_args = CPUArgs(\"../../graphStatisticsFinal.csv\",graph_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['73730 142944 94629 165694 170215 157030 100578',\n",
       " '168659 136316 36027 116835 63253 42457 19086',\n",
       " '170410 54697 183110 262990 278178 279803 168804',\n",
       " '174852 313830 82150 220506 78658 274848 312597',\n",
       " '673421 295426 857898 316803 139665 918619 880160',\n",
       " '941641 1341842 968483 174369 1042925 298843 260848',\n",
       " '117120 1069949 1422676 1505935 1665532 1517341 835452',\n",
       " '1236070 1994147 2272307 1967706 1123845 395257 1724213',\n",
       " '1154710 420314 2999380 1672218 2585736 1881330 3630921',\n",
       " '821868 2539355 2470345 3303316 3801386 2294618 604277',\n",
       " '120522 2431199 5765351 2288264 5370942 823817 856045']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed:  graph7\n",
      "completed:  graph8.txt\n",
      "completed:  fat200\n",
      "completed:  GSE1730_q\n",
      "completed:  GSE10158_q\n",
      "completed:  orani\n",
      "completed:  ego-facebook\n",
      "completed:  grqc_q\n",
      "completed:  uc64\n",
      "completed:  government\n",
      "completed:  wiki-elec\n",
      "completed:  lastfm\n",
      "completed:  hepPh\n",
      "completed:  astroPh\n",
      "completed:  condmat\n",
      "completed:  Enron_q\n",
      "completed:  fb-pages\n",
      "completed:  brightkite\n",
      "completed:  livemocha\n",
      "completed:  gowalla\n",
      "completed:  citeseer\n",
      "completed:  com-dblp\n",
      "completed:  amazon_q\n",
      "completed:  youtube_q\n",
      "completed:  hyves_q\n",
      "completed:  skitter\n",
      "completed:  flixster\n",
      "completed:  patent_q\n",
      "completed:  soc-livejournal\n",
      "completed:  dblp-author\n",
      "Done yay! :)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path=\"../client/query/rand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ = open(os.path.join(path,\"GSE10158_q\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file_.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3 6 192 1 1',\n",
       " '6 9 467 1 1',\n",
       " '9 12 749 1 1',\n",
       " '12 15 1396 1 1',\n",
       " '15 18 820 1 1',\n",
       " '18 21 15 1 1',\n",
       " '21 24 446 1 1',\n",
       " 'server_exit']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../dataandargs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed:  fat200\n",
      "completed:  GSE1730_q\n",
      "completed:  GSE10158_q\n",
      "completed:  orani\n",
      "completed:  ego-facebook\n",
      "completed:  grqc_q\n",
      "completed:  government\n",
      "completed:  wiki-elec\n",
      "completed:  lastfm\n",
      "completed:  hepPh\n",
      "completed:  condmat\n",
      "completed:  Enron_q\n",
      "completed:  citeseer\n",
      "completed:  com-dblp\n",
      "completed:  dblp-author\n",
      "completed:  astroPh\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../client/query/exp1_2\"\n",
    "for graph_name in df['Graph'].unique():\n",
    "    temp = df[df['Graph']==graph_name]\n",
    "    query_data = \"\"\n",
    "    for row in temp.iterrows():\n",
    "        n1,n2,qid = row[1][\"N1\"], row[1][\"N2\"], row[1][\"QID\"] \n",
    "        query = f\"{n1} {n2} {qid} 1 1\\n\"\n",
    "        query_data += query\n",
    "    query_data+=\"server_exit\"\n",
    "    with open(os.path.join(output_dir,graph_name),'w') as f:\n",
    "        f.write(query_data)\n",
    "    print(\"completed: \",graph_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6 1 1 1\n",
      "6 9 1 1 1\n",
      "9 12 1 1 1\n",
      "12 15 1 1 1\n",
      "15 18 1 1 1\n",
      "18 21 1 1 1\n",
      "21 24 1 1 1\n",
      "server_exit\n"
     ]
    }
   ],
   "source": [
    "print(query_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6, 1443)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[1][\"N1\"], row[1][\"N2\"], row[1][\"QID\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GpuClientArgs(path,graph_names,output_dir,postfix=\"1 1\"):\n",
    "    df = pd.read_csv(path)\n",
    "    for graph_name in graph_names:\n",
    "        query_data = ''\n",
    "        num_vertex = df[df['file_name']==graph_name]['V'].values[0]\n",
    "        for N1,N2 in zip([3,6,9,12,15,18,21],[6,9,12,15,18,21,24]):\n",
    "            qid = np.random.randint(0,num_vertex)\n",
    "            query = f\"{N1} {N2} {qid} {postfix}\\n\"\n",
    "            query_data +=query\n",
    "        query_data+=\"server_exit\"\n",
    "        with open(os.path.join(output_dir,graph_name),'w') as f:\n",
    "            f.write(query_data)\n",
    "        print(\"completed: \",graph_name)\n",
    "    print(\"Done yay! :)\")\n",
    "x = GpuClientArgs(\"../../graphStatisticsFinal.csv\",graph_names,\"../client/query/rand\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_exp3(arg,graph):\n",
    "    final = \"server_exit\"\n",
    "    save_dir = \"../client/query/exp3/\"\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    current = arg*100\n",
    "    current = current +[final]\n",
    "    with open(os.path.join(save_dir,graph),\"w\") as file:\n",
    "        file.write(\"\\n\".join(current))\n",
    "args_exp3(['9 12 79920 1 1'],'com-dblp')\n",
    "args_exp3(['9 12 321 1 1'],\"amazon_q\")\n",
    "args_exp3(['9 12 1452 1 1'],'orani')\n",
    "args_exp3(['9 12 1127 1 1'],\"ego-facebook\")\n",
    "args_exp3(['9 12 6876 1 1'],\"government\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_exp7(arg,graph):\n",
    "    final = \"server_exit\"\n",
    "    save_dir = \"../client/query/exp7/\"\n",
    "    current = arg*10\n",
    "    current = current +[final]\n",
    "    with open(os.path.join(save_dir,graph),\"w\") as file:\n",
    "        file.write(\"\\n\".join(current))\n",
    "args_exp7(['9 12 1127 1 1'],\"ego-facebook\")\n",
    "args_exp7(['9 12 6876 1 1'],\"government\")\n",
    "args_exp7(['9 12 321 1 1'],\"amazon_q\")\n",
    "args_exp7(['9 12 1452 1 1'],'orani')\n",
    "args_exp7(['9 12 79920 1 1'],'com-dblp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_exp8(arg,graph):\n",
    "    final = \"server_exit\"\n",
    "    save_dir = \"../client/query/exp8/\"\n",
    "    current = arg*10\n",
    "    current = current +[final]\n",
    "    with open(os.path.join(save_dir,graph),\"w\") as file:\n",
    "        file.write(\"\\n\".join(current))\n",
    "args_exp8(['9 12 1127 1 1'],\"ego-facebook\")\n",
    "args_exp8(['9 12 6876 1 1'],\"government\")\n",
    "args_exp8(['9 12 321 1 1'],\"amazon_q\")\n",
    "args_exp8(['9 12 1452 1 1'],'orani')\n",
    "args_exp8(['9 12 79920 1 1'],'com-dblp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# need to change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change\n",
    "def args_exp3(arg,graph):\n",
    "    final = \"server_exit\"\n",
    "    \n",
    "    save_dir = \"../client/query/exp3/\"\n",
    "    save_dir = os.path.join(save_dir,graph)\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    for i in range(10,110,10):\n",
    "        current = arg*i\n",
    "        current = current +[final]\n",
    "        with open(os.path.join(save_dir,str(i)+\".txt\"),\"w\") as file:\n",
    "            file.write(\"\\n\".join(current))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change\n",
    "args_exp3(['9 12 321 1 1'],\"amazon_q\")\n",
    "args_exp3(['9 12 1452 1 1'],'orani')\n",
    "args_exp3(['9 12 79920 1 1'],'com-dblp')\n",
    "args_exp3(['9 12 1127 1 1'],\"ego-facebook\")\n",
    "args_exp3(['9 12 6876 1 1'],\"government\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_exp5(qid,graph):\n",
    "    final = \"server_exit\"\n",
    "    \n",
    "    save_dir = \"../client/query/exp5/\"\n",
    "    save_dir = os.path.join(save_dir,graph)\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    for n1,n2 in zip([3,6,9,12,15,18,21],[6,9,12,15,18,21,24]):\n",
    "        current = list(map(str,[n1,n2,qid,1,1]))\n",
    "        current = \" \".join(current)\n",
    "        current = [current]*10\n",
    "        current += [final]\n",
    "        with open(os.path.join(save_dir,str(n1)+\"_\"+str(n2)+\".txt\"),\"w\") as file:\n",
    "            file.write(\"\\n\".join(current))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_exp5(1127,\"ego-facebook\")\n",
    "args_exp5(321,\"amazon_q\")\n",
    "args_exp5(6876,\"government\")\n",
    "args_exp5(1452,'orani')\n",
    "args_exp5(79920,'com-dblp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def read_graph_file(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        next(f)  # Skip the first line\n",
    "        return [tuple(map(int, line.split())) for line in f]\n",
    "    \n",
    "edges = read_graph_file(\"../data/hepPH_SCS\")\n",
    "\n",
    "G = nx.Graph(edges)  # 100 nodes, 10% chance of edge creation\n",
    "\n",
    "\n",
    "clustering_coeffs = nx.clustering(G)\n",
    "\n",
    "dense_node = max(clustering_coeffs, key=clustering_coeffs.get)\n",
    "print(f\"Node in dense area (highest clustering coefficient): {dense_node}, Clustering Coefficient: {clustering_coeffs[dense_node]}\")\n",
    "\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "central_node = max(degree_centrality, key=degree_centrality.get)\n",
    "print(f\"Node in dense area (highest degree centrality): {central_node}, Degree Centrality: {degree_centrality[central_node]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
